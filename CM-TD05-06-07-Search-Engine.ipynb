{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15b2cf7-f9e4-43ea-8be8-9b6239d2fa6b",
   "metadata": {},
   "source": [
    "# Characters Search Engine\n",
    "\n",
    "To disambiguate the characters of Game of Thrones books, we need to have an authoritative source, curated and verified containing the final list of all characters. \n",
    "\n",
    "This list exist in the [wiki of ice and fire](https://awoiaf.westeros.org). So we want to build a search engine based on this wiki to send a character partial name and get the most corresponding list of potential characters, ranked. \n",
    "\n",
    "Many methods for ranking exists, from the search engine specific network analysis to building a custom function. Like all modern search engine, we will create our own ranking algorithm that will use many features as based data. \n",
    "\n",
    "To create our search engine we need to follow the following steps:\n",
    "1. Download the HTML page for each character\n",
    "2. Scrape the HTML page and extract relevant informations using beautiful soup\n",
    "3. create the network of characters to create the page rank feature \n",
    "4. create the Bag of Words (BOW) that will be the basis for the search engine\n",
    "5. optimize the search engine using our list of features \n",
    "\n",
    "## 1. Download the HTML page for each character\n",
    "\n",
    "To download the characters we need to do it in two steps:\n",
    "1. get a list of pages we shall scrape\n",
    "2. scrape all the pages\n",
    "\n",
    "### 1.1. Get the list of characters\n",
    "\n",
    "Let's start by importing the required libraries to perform this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a49418-daf3-458d-a310-27fed30c5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda78a1b-6473-464a-94a4-cc80de2398c7",
   "metadata": {},
   "source": [
    "To not be stopped by the awoif website, we hide ourselves very simply by changing the default python requests User-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a28b78-2326-46e0-a584-fb3c17687691",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://awoiaf.westeros.org/index.php/List_of_characters'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecce8e-44c8-4ab3-857c-9aa47fb9646f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We perfom the requests including our custom headers. headers can be omitted if you do not need to hide that you are a robot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d313e-2fbb-4112-9fcf-2bc3ae67619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c2d8f-5531-43dd-94ec-ec915611680b",
   "metadata": {},
   "source": [
    "Finally we test the status of the server result and continue if we get a code 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09422e-7244-4db7-b706-5cb19944c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if r.status_code == 200:\n",
    "    print('request is a success')\n",
    "else:\n",
    "    print('request is a failure, status code is',r.status_code,' and error is', r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31cae3-aacc-4694-a88c-746d2e635e28",
   "metadata": {},
   "source": [
    "The next step is to mount the DOM of the text. This is done using BeautifulSoup. \n",
    "\n",
    "Then we get to extract the list of link either using the find method to navigate the DOM tree or using the css selectors. we choose the latter.\n",
    "\n",
    "A list in HTML is tagged as UL (Unordered List) and each item is tagged as LI (List Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634e559-b8b5-4d41-8ef0-7fb4eb928269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the soup \n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "# find the li\n",
    "links = soup.select('div.mw-parser-output li')[26:]\n",
    "\n",
    "# find all relative links in each li and recreate an absolute path for all \n",
    "links_for_df = [f\"https://awoiaf.westeros.org{link.find('a').attrs['href']}\" for link in links]\n",
    "\n",
    "# create a dataframe out of the list\n",
    "records = {'characters_url':links_for_df}\n",
    "dfscrape = pd.DataFrame.from_records(records)\n",
    "\n",
    "# create a column to hold the scraped or not scraped status\n",
    "dfscrape['scraped'] = False\n",
    "\n",
    "# create a characters column to save the character page name for the future link analysis\n",
    "dfscrape['characters'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9e1ee-fbea-43d5-8e46-35d5dfdec897",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscrape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e01e1-89a0-4684-b295-de4d2c1781ae",
   "metadata": {},
   "source": [
    "### 1.2 Get every characters webpage\n",
    "\n",
    "for every link we found, it is time to get the page and store the resulting html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aef67c-8755-49a6-ab0a-32a25d32d1ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    r = requests.get(url, headers=headers)\n",
    "    if r.status_code != 200:\n",
    "        print(f'request {url} is a failure, status code is {r.status_code} and error is {r.text}')\n",
    "    time.sleep(0.1)\n",
    "    return r.text\n",
    "\n",
    "for i,row in dfscrape[~dfscrape.scraped].iterrows():\n",
    "    html = get_page(row['characters_url'])\n",
    "    dfscrape.iat[i,2] = html\n",
    "    dfscrape.iat[i,1] = True\n",
    "    break # REMOVE THIS LINE IF YOU WANT TO EXECUTE ALL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e57cc-e331-4352-81b0-d5dcce02da5c",
   "metadata": {},
   "source": [
    "finally after all is downloaded, we create files for each character, using the character name as a filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3faf61-1f1c-440b-8b06-1dd7805391bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in dfscrape.iterrows():\n",
    "    filename = r['characters_url'].split('/')[-1]\n",
    "    html = r['characters']\n",
    "    with open(os.path.join('data','html_recent',filename),'w+') as fp:\n",
    "        fp.write(html)\n",
    "        fp.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcff68-add5-46da-8aa3-c4205e667580",
   "metadata": {},
   "source": [
    "## 2. Scrape the HTML page and extract relevant informations using beautiful soup\n",
    "\n",
    "Now that we have a directory containing all the html pages, we can read all files and convert it in a soup. \n",
    "\n",
    "From the soup we can extract all required informations\n",
    "\n",
    "List of information to get from every page: \n",
    "1. title of the page\n",
    "2. infobox name\n",
    "3. aliases\n",
    "4. page rank -> need to get Links to other pages\n",
    "5. length of the text\n",
    "6. books\n",
    "7. mentionned or appear in each book\n",
    "8. __the main text CLEANED__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57a029-9088-4d05-8de2-947b44bbe1df",
   "metadata": {},
   "source": [
    "### 2.1 HTML files into soup into dataframe\n",
    "\n",
    "Read each html and make a soup out of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "73fa92bb-107a-401f-842d-f878cd5afbb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "soups = []\n",
    "pages = []\n",
    "\n",
    "# walk through all the files in directory and for each, get the soup \n",
    "for dirpath, dirnames, filenames in os.walk('data/html_recent'):\n",
    "    for filename in filenames:\n",
    "        # we make sure the filename do not start with a dot as only hidden files do\n",
    "        if not filename.startswith('.'): \n",
    "            pages.append(filename)  \n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            with open(filepath,'r', encoding='utf-8') as fp:\n",
    "                html = fp.read()\n",
    "                soup = BeautifulSoup(html)\n",
    "                soups.append(soup)\n",
    "df = pd.DataFrame.from_dict({'soup':soups, 'page':pages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5833e9-652d-4c5b-af06-22e0a78d88e3",
   "metadata": {},
   "source": [
    "### 2.2 get features\n",
    "\n",
    "based on the soup, we get all possible features\n",
    "\n",
    "The most complicated one is the infobox that we transform into a dictionary object to anaylze it further later\n",
    "\n",
    "we also define a clean text function to get only the useful words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "7a851437-9671-4c67-9ca9-adee4034f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    clean_text = text.lower()\n",
    "\n",
    "    #remove punctuation\n",
    "    clean_text = re.sub(r\"[^\\w\\s]\",\"\",clean_text)\n",
    "\n",
    "    # Remove Unicode like unwanted characters\n",
    "    clean_text = re.sub(r'[^\\x00-\\x7F]+', ' ',clean_text)\n",
    "\n",
    "    # remove new line\n",
    "    clean_text = re.sub(r'[\\n]+', ' ',clean_text)\n",
    "\n",
    "    # remove numbers\n",
    "    clean_text = re.sub(r'[\\d]+', ' ',clean_text)\n",
    "\n",
    "    # normalize spaces\n",
    "    clean_text = re.sub(r'[\\s]+', ' ',clean_text)\n",
    "\n",
    "    # remove stopwords whose frequency is too high\n",
    "    with open('data/stopwords_en.txt','r') as fp:\n",
    "        stopwords = [w.strip() for w in fp.readlines()]\n",
    "    clean_text = [word for word in clean_text.split() if word not in stopwords]\n",
    "    \n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "5ab2a87e-bf4e-4f72-a7f1-03294633c89a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qoren Martell\n",
      " the Dread\n",
      "{'aliases': ['the imp', 'halfman', 'boyman', 'giant of lannister', 'lord imp', \"lord tywin's doom\", \"lord tywin's bane\", 'yollo', 'hugor hill', 'hugor halfwit', 'no-nose', 'freak', 'redhands', 'ser imp', 'monkey demon', 'the bloody hand', 'the demonic dwarf'], 'titles': ['Acting ', 'Hand of the King', ' ', '(formerly)', 'Master of coin', ' ', '(formerly)', 'Lord of Casterly Rock', ' ', '(claimant)'], 'allegiances': 'House Lannister\\nSecond Sons', 'predecessor': 'Petyr Baelish\\n \\n(master of coin)', 'successor': 'Gyles Rosby\\n \\n(master of coin)', 'culture': 'Westermen', 'born': 'In\\xa0\\n273\\xa0AC\\n\\n\\n,\\xa0\\nCasterly Rock\\n', 'father': 'Lord \\nTywin Lannister', 'mother': 'Lady \\nJoanna Lannister', 'spouses': '1\\nst\\n: \\nTysha\\n \\n(annulled)\\n2\\nnd\\n: \\nSansa Stark', 'lover': 'Shae', 'personal arms': 'A golden hand in a circle of golden lions on red\\n\\n(Gules, a hand or, environed by lions or)', 'books': {'The World of Ice & Fire': 'mentioned', 'A Game of Thrones': 'POV', 'A Clash of Kings': 'POV', 'A Storm of Swords': 'POV', 'A Feast for Crows': 'mentioned', 'A Dance with Dragons': 'POV', 'The Winds of Winter': 'POV'}, 'played by': 'Peter Dinklage', 'tv series': 'Game of Thrones\\n:\\n1\\n | \\n2\\n | \\n3\\n | \\n4\\n | \\n5\\n | \\n6\\n | \\n7\\n | \\n8'}\n",
      "[]\n",
      "743\n",
      "{'The World of Ice & Fire': 'mentioned', 'A Game of Thrones': 'POV', 'A Clash of Kings': 'mentioned', 'A Storm of Swords': 'mentioned', 'A Feast for Crows': 'mentioned', 'A Dance with Dragons': 'mentioned', 'The Winds of Winter': 'mentioned'}\n",
      "gwayne iii gardener called fat king reach head house gardener gwayne persuaded lord peake lord manderly accept judgement quarrel fealty lands bloodshed annals history gwayne iii gardener writ\n",
      "['Stannis_Baratheon', 'Asha_Greyjoy', 'Torghen_Flint', 'Donnel_Flint']\n"
     ]
    }
   ],
   "source": [
    "pages = df.page.to_list()\n",
    "\n",
    "def get_title_name(soup): \n",
    "    return soup.find(\"h1\").get_text(' ',strip=True).strip()\n",
    "\n",
    "def get_infobox_name(soup):\n",
    "    try:\n",
    "        return soup.find('div', id='mw-content-text').table.find('th',{'colspan':2}).get_text('|').strip().split('|')[-1]\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "def get_aliases_name(infobox):\n",
    "    return infobox.get('aliases',[])\n",
    "    \n",
    "def get_infobox(soup):\n",
    "    try:\n",
    "        ths = soup.find('div', id='mw-content-text').table.find_all('th',{\"scope\" : \"row\"} )\n",
    "    except AttributeError:\n",
    "        return {}\n",
    "\n",
    "    infobox = {th.get_text().lower():re.sub(r\"\\[\\d+\\]\", '', th.next_sibling.get_text('\\n').strip()) for th in ths}\n",
    "    \n",
    "    if infobox.get('book') is not None:\n",
    "        infobox['books'] = infobox['book']\n",
    "        del infobox['book']\n",
    "    \n",
    "    if infobox.get('books') is not None:\n",
    "        books = infobox.get('books')\n",
    "        books = re.sub(r\"((\\n)\\s\\()|(\\n\\s\\n\\()\", '-', books, 0, re.MULTILINE).replace(')','').split('\\n')\n",
    "        books = {b.split('-')[0]:b.split('-')[-1] for b in books}\n",
    "        infobox['books'] = books\n",
    "    \n",
    "    if infobox.get('alias') is not None:\n",
    "        infobox['aliases'] = infobox['alias']\n",
    "        del infobox['alias']   \n",
    "    \n",
    "    if infobox.get('aliases') is not None:\n",
    "        infobox['aliases'] = [al.lower() for al in infobox.get('aliases').split('\\n') if len(al)>0]\n",
    "    else:\n",
    "        infobox['aliases'] = []\n",
    "\n",
    "    if infobox.get('title') is not None:\n",
    "        infobox['titles'] = infobox['title']\n",
    "        del infobox['title']\n",
    "    \n",
    "    if infobox.get('titles') is not None:\n",
    "        infobox['titles'] = [al for al in infobox.get('titles').split('\\n') if len(al)>0]\n",
    "    return infobox \n",
    "\n",
    "def get_text_length(soup):\n",
    "    return len(' '.join([p.get_text() for p in soup.find_all(\"p\")]))\n",
    "\n",
    "def get_books(infobox):\n",
    "    return infobox.get('books',{})\n",
    "\n",
    "def get_text(soup):\n",
    "    return clean(' '.join([p.get_text() for p in soup.find_all(\"p\")]))\n",
    "\n",
    "def get_links(soup):\n",
    "    links = soup.find_all('a')\n",
    "    links = [link for link in links if link.attrs.get('href') is not None]\n",
    "    links = [link['href'].split('/')[-1] for link in links if link['href'].split('/')[-1] in pages and link['href'].startswith('/index')]\n",
    "    return list(set(links))\n",
    "\n",
    "print(get_title_name(df.sample(1).soup.values[0]))\n",
    "print(get_infobox_name(df.sample(1).soup.values[0]))\n",
    "print(get_infobox(df.loc[2197].soup))\n",
    "print(get_aliases_name(get_infobox(df.sample(1).soup.values[0])))\n",
    "print(get_text_length(df.sample(1).soup.values[0]))\n",
    "print(get_books(get_infobox(df.loc[174].soup)))\n",
    "print(get_text(df.sample(1).soup.values[0]))\n",
    "print(get_links(df.sample(1).soup.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3e9e5-7818-4053-b038-983bb9578e74",
   "metadata": {},
   "source": [
    "### 2.3 Fill the features in the dataframe\n",
    "\n",
    "Now that each function is using the soup OR the infobox dictionary, we can create the features inside the dataframe\n",
    "\n",
    "Pay attention to the column used in the apply, most of the time it is the _soup_ but for __books__ and __aliases__ it is the _infobox_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "b1d01dfd-bb66-4462-ad18-46778721399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df.soup.apply(get_title_name)\n",
    "df['infobox_name'] = df.soup.apply(get_infobox_name)\n",
    "df['infobox'] = df.soup.apply(get_infobox)\n",
    "df['aliases_names'] = df.infobox.apply(get_aliases_name)\n",
    "df['text_length'] = df.soup.apply(get_text_length)\n",
    "df['books'] = df.infobox.apply(get_books)\n",
    "df['text'] = df.soup.apply(get_text)\n",
    "df['links'] = df.soup.apply(get_links)\n",
    "df['infobox_length'] = df.infobox.apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97322f-b2a2-4555-9f55-601773ba38c0",
   "metadata": {},
   "source": [
    "### 2.4 Save everything except the soup into a pickle for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "20255368-c986-4703-a194-09d113e900eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['soup', 'page', 'title', 'infobox_name', 'infobox', 'aliases_names',\n",
       "       'text_length', 'books', 'text', 'links', 'infobox_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "120f36ca-1eaf-429f-b46e-0ed57b3ec55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[1:]].to_pickle('awoif_heavy.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338bda9c-afd9-4427-89cc-e51dd812a9ac",
   "metadata": {},
   "source": [
    "### 2.5 LOAD THE PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5615700d-c026-47f4-874e-2e2e1f824851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('awoif_heavy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "efaa2305-cb0a-4216-9567-c0855412023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/fabien/.pyenv/versions/3.11.0/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/fabien/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from scipy) (1.23.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a6adc-c3c4-4226-9bc6-22eb40576994",
   "metadata": {},
   "source": [
    "## 3 create a network to have network ranking features\n",
    "\n",
    "The network has to be created using pages and links in the pages. \n",
    "\n",
    "### 3.1 create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1a11ca-5f37-49ee-9b0d-4fe21b4ed29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c6a7cb-fa74-4f7b-9423-0ae87b5919e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e26334-8428-4d14-a14e-d4fd7322bad8",
   "metadata": {},
   "source": [
    "for each page for each character we add all the links to other characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aeea123-e7a4-4a79-b81c-fdc2e7169d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    page = r['page']\n",
    "    for l in r['links']:\n",
    "        G.add_edge(page, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d67198-81d5-46e0-a74b-07c28548312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–– Network Characteristics –– \n",
      "\tNodes: 3468\n",
      "\tEdges: 53079\n"
     ]
    }
   ],
   "source": [
    "print('–– Network Characteristics –– ')\n",
    "print(f'\\tNodes: {G.number_of_nodes()}')\n",
    "print(f'\\tEdges: {G.number_of_edges()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb78c37-42a4-4415-92db-14fcfc024d36",
   "metadata": {},
   "source": [
    "### 3.2 Calculate PageRank, Closeness Centrality and Betweeness Centrality\n",
    "\n",
    "To calculate pageRank and centralities, refer to [networkx documentation](https://networkx.org/documentation/latest/ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b6397-9e8b-4405-97d0-df4e383f86dc",
   "metadata": {},
   "source": [
    "start with the pagerank and store it in a variable called __pr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3470107c-6df0-4ef2-8655-55b4086fa4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659e6e3-1701-45b9-ae17-446c0089c345",
   "metadata": {},
   "source": [
    "continue with the betweeness centrality and store it in a variable called __bc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4159ce65-45db-4ffa-87a1-5afc7c57b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a13c8-a5d3-4d7a-8448-62e94b53b8d8",
   "metadata": {},
   "source": [
    "finish with the closeness centrality and store it in a variable called __cc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a698c3f7-2444-4b5d-81d4-adc813caebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add986b6-8858-4105-9dce-92c19afa150c",
   "metadata": {},
   "source": [
    "### 3.3 add each score as a new columns for all the pages in the dataframe\n",
    "\n",
    "the columns shall be named respectively __pagerank__, __betweeness__, __closeness__\n",
    "\n",
    "the pr, bc and cc are all dictionaries keyed with page name. \n",
    "\n",
    "The page name is in the column page of the dataframe sor make good use of:\n",
    " - apply function for dataframes\n",
    " - get function for dictionaries\n",
    " - lambda function from python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec915c2-4ff0-41f6-92a8-326d2cbfa876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pagerank'] = df.page.apply(lambda x: pr.get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0564af7-1e41-4359-92cd-c891d139cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['betweeness'] = df.page.apply(lambda x: pr.get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24014f96-ddd4-4ac5-b7d2-297df92aa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['closeness'] = df.page.apply(lambda x: cc.get(x,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d114b9-aa39-4068-903c-0a80b5f4124d",
   "metadata": {},
   "source": [
    "### 3.4 check the influence of each network indicator\n",
    "\n",
    "To measure the influence of each indicator, or the indicator bringing more information, we can start by checking if these indicators are correlated\n",
    "\n",
    "Find the correlation between these 3 columns, what do you observe? \n",
    "\n",
    "_Hint: pandas as a correlation function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3f5d6cd-db55-456b-8049-17b4498027b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweeness</th>\n",
       "      <th>closeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pagerank</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betweeness</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closeness</th>\n",
       "      <td>0.436078</td>\n",
       "      <td>0.436078</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pagerank  betweeness  closeness\n",
       "pagerank    1.000000    1.000000   0.436078\n",
       "betweeness  1.000000    1.000000   0.436078\n",
       "closeness   0.436078    0.436078   1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['pagerank', 'betweeness', 'closeness']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf76ae-33f0-430a-b968-ba3c23bb4597",
   "metadata": {},
   "source": [
    "Our space has 3 dimensions right now. We can use Principal component Analysis PCA to evaluate the information each variable bring.\n",
    "\n",
    "Apply PCA method from sklearn to our 3 columns. see pdf join and [sklearn PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "What can you conclude? Do we need the 3 variables? Which one explain the variance the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc6f8c30-7a14-4cf2-9220-d03a7b27d44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(df[['pagerank', 'betweeness', 'closeness']].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c15b9d-2610-48aa-8d73-255051ed5a6b",
   "metadata": {},
   "source": [
    "Print the explained variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d13cff88-d786-405a-b7b6-a788cd56a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99974784e-01, 2.52158731e-05])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c84d9-161c-4825-b20e-8fc78da0bed6",
   "metadata": {},
   "source": [
    "print the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50100ac7-67b0-4966-b012-e43191e1461e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0017207 ,  0.0017207 ,  0.99999704],\n",
       "       [ 0.70710469,  0.70710469, -0.00243344]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40ace7-f0ad-448c-aeba-6dec94a54ced",
   "metadata": {},
   "source": [
    "To finish, let's plot the histogram of the network scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e79d7e8a-ef07-45bb-bb15-45ed71ae15a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "ax = sns.histplot(df[['pagerank', 'betweeness', 'closeness']], bins=100)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb68df3-3853-4b64-91b4-d6b3fd397325",
   "metadata": {},
   "source": [
    "## 3.5 create a custom distance \n",
    "\n",
    "Let's compare the ranking performance of our network indicator together\n",
    "\n",
    "First create a combination of the three score, using an euclidean and a minkowski distance.\n",
    "\n",
    "Why is it is done from 0,0,0 to something ? \n",
    "\n",
    "Why is axis = 1 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a7d792-1aec-4390-851a-4507b05c2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "df['euclidean'] = df[['pagerank', 'betweeness', 'closeness']].apply(lambda x : distance.euclidean([0,0,0],x.to_numpy()), axis=1)\n",
    "df['minkowski'] = df[['pagerank', 'betweeness', 'closeness']].apply(lambda x : distance.minkowski([0,0,0],x.to_numpy()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de224f-5c49-45f4-a413-c4c2e255fa8a",
   "metadata": {},
   "source": [
    "now we create a custom function that takes a list of pages, and return the top 10 according to the chosen ranking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d2037d-72c4-4414-9d56-364b9ca3fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_these_pages(pages_list, method='euclidean'):\n",
    "    results = df.loc[pages_list,:].sort_values(by=[method],ascending=False)[:10]\n",
    "    return list(results.page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a8502-5e49-4f9a-b1e8-63d4977ce382",
   "metadata": {},
   "source": [
    "at last we create a dataframe to easily see the difference between the ranking methods. \n",
    "\n",
    "What can you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7bae610-fcd5-4a39-80cf-e8b509f42cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweeness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>minkowski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tyrion_Lannister</td>\n",
       "      <td>Tyrion_Lannister</td>\n",
       "      <td>Stannis_Baratheon</td>\n",
       "      <td>Stannis_Baratheon</td>\n",
       "      <td>Stannis_Baratheon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stannis_Baratheon</td>\n",
       "      <td>Stannis_Baratheon</td>\n",
       "      <td>Tyrion_Lannister</td>\n",
       "      <td>Tyrion_Lannister</td>\n",
       "      <td>Tyrion_Lannister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daenerys_Targaryen</td>\n",
       "      <td>Daenerys_Targaryen</td>\n",
       "      <td>Robb_Stark</td>\n",
       "      <td>Robb_Stark</td>\n",
       "      <td>Robb_Stark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jaime_Lannister</td>\n",
       "      <td>Jaime_Lannister</td>\n",
       "      <td>Joffrey_Baratheon</td>\n",
       "      <td>Joffrey_Baratheon</td>\n",
       "      <td>Joffrey_Baratheon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arya_Stark</td>\n",
       "      <td>Arya_Stark</td>\n",
       "      <td>Tommen_Baratheon</td>\n",
       "      <td>Tommen_Baratheon</td>\n",
       "      <td>Tommen_Baratheon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jon_Snow</td>\n",
       "      <td>Jon_Snow</td>\n",
       "      <td>Daenerys_Targaryen</td>\n",
       "      <td>Daenerys_Targaryen</td>\n",
       "      <td>Daenerys_Targaryen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cersei_Lannister</td>\n",
       "      <td>Cersei_Lannister</td>\n",
       "      <td>Eddard_Stark</td>\n",
       "      <td>Eddard_Stark</td>\n",
       "      <td>Eddard_Stark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eddard_Stark</td>\n",
       "      <td>Eddard_Stark</td>\n",
       "      <td>Cersei_Lannister</td>\n",
       "      <td>Cersei_Lannister</td>\n",
       "      <td>Cersei_Lannister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tywin_Lannister</td>\n",
       "      <td>Tywin_Lannister</td>\n",
       "      <td>Jaime_Lannister</td>\n",
       "      <td>Jaime_Lannister</td>\n",
       "      <td>Jaime_Lannister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Robb_Stark</td>\n",
       "      <td>Robb_Stark</td>\n",
       "      <td>Tywin_Lannister</td>\n",
       "      <td>Tywin_Lannister</td>\n",
       "      <td>Tywin_Lannister</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pagerank          betweeness           closeness  \\\n",
       "0    Tyrion_Lannister    Tyrion_Lannister   Stannis_Baratheon   \n",
       "1   Stannis_Baratheon   Stannis_Baratheon    Tyrion_Lannister   \n",
       "2  Daenerys_Targaryen  Daenerys_Targaryen          Robb_Stark   \n",
       "3     Jaime_Lannister     Jaime_Lannister   Joffrey_Baratheon   \n",
       "4          Arya_Stark          Arya_Stark    Tommen_Baratheon   \n",
       "5            Jon_Snow            Jon_Snow  Daenerys_Targaryen   \n",
       "6    Cersei_Lannister    Cersei_Lannister        Eddard_Stark   \n",
       "7        Eddard_Stark        Eddard_Stark    Cersei_Lannister   \n",
       "8     Tywin_Lannister     Tywin_Lannister     Jaime_Lannister   \n",
       "9          Robb_Stark          Robb_Stark     Tywin_Lannister   \n",
       "\n",
       "            euclidean           minkowski  \n",
       "0   Stannis_Baratheon   Stannis_Baratheon  \n",
       "1    Tyrion_Lannister    Tyrion_Lannister  \n",
       "2          Robb_Stark          Robb_Stark  \n",
       "3   Joffrey_Baratheon   Joffrey_Baratheon  \n",
       "4    Tommen_Baratheon    Tommen_Baratheon  \n",
       "5  Daenerys_Targaryen  Daenerys_Targaryen  \n",
       "6        Eddard_Stark        Eddard_Stark  \n",
       "7    Cersei_Lannister    Cersei_Lannister  \n",
       "8     Jaime_Lannister     Jaime_Lannister  \n",
       "9     Tywin_Lannister     Tywin_Lannister  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_data = {'pagerank':rank_these_pages(df.index, method='pagerank'), \n",
    "                'betweeness':rank_these_pages(df.index, method='betweeness'),\n",
    "                'closeness':rank_these_pages(df.index, method='closeness'),\n",
    "                'euclidean':rank_these_pages(df.index, method='euclidean'),\n",
    "                'minkowski':rank_these_pages(df.index, method='minkowski')}\n",
    "df_ranking = pd.DataFrame.from_dict(ranking_data)\n",
    "df_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd637f-4b39-4779-b9bf-acc75be26570",
   "metadata": {},
   "source": [
    "## 4 documents matching a query\n",
    "\n",
    "A search engine dissociate the documents corresponding to a query from the ranking of these documents. \n",
    "\n",
    "Henceforth, before we can rank documents according to a query, wee need to be able to retrieve all document that correspond to a query.\n",
    "\n",
    "To do this we have many solutions:\n",
    "1. dumb solution is to look for the work in the documents using a simple test of the word or group of words in the text.\n",
    "2. the __easiest__ is to compare the words of the query with the text and return documents containing the text. Popular methods to do this are:\n",
    "    - Jaccard Similarity\n",
    "    - w-shingling\n",
    "    - Pearson Similarity\n",
    "    - Levenshtein distance\n",
    "    - Normalized Google Distance \n",
    "3. more advanced method include vectorizations. The documents are summarized into vectors and the similarity is not with the words but with vectors representing the words:\n",
    "    - Count vectorizer\n",
    "    - TFIDF vectorizer\n",
    "    - Word2vec\n",
    "    - Embeddings (BERT)\n",
    "5. Lastly, and this is how the search engine would work, you use a clever mix of prior knowledge and custom features together with the text and the vectorization, and of course the ranking features. \n",
    "\n",
    "For these examples we will use the word __'ned'__ and __'the queen's hand'__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51fc6c-c25e-410f-9aaf-3e4e5b39096f",
   "metadata": {},
   "source": [
    "### 4.1 Dumb Solution find \n",
    "\n",
    "we write a function that look if the query word are both in the text, aliases and names, and send back index of documents that match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8661678-40f5-4561-9589-08f7c2e5d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bow'] = df['text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563a36a1-975d-4b8c-9302-79d901f7d3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ned\n",
      "52 3669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "174     Eddard_Stark\n",
       "282    Hallis_Mollen\n",
       "352     Lyanna_Stark\n",
       "355            Quent\n",
       "402      Edric_Dayne\n",
       "Name: page, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = 'ned'\n",
    "query2 = \"queen hand\"\n",
    "\n",
    "def dumb_find(query):\n",
    "    masks = []\n",
    "    for q in query.split():\n",
    "        print(q)\n",
    "        mask = [q in ws for ws in df['bow']]\n",
    "        masks.append(mask)\n",
    "        print(sum(mask), len(mask))\n",
    "    \n",
    "    mask = [all(tup) for tup in zip(*masks)]\n",
    "    mask_alias = [query in ws for ws in df['aliases_names'] if ws is not None]\n",
    "    mask_title = df.title.str.contains(f\"\\b{query}\\b\", case=False, regex=True)\n",
    "    mask_infobox_name = df.infobox_name.str.contains(f\"\\b{query}\\b\", case=False, regex=True)\n",
    "    final_mask = [any(tup) for tup in zip(mask, mask_alias, mask_title, mask_infobox_name)]\n",
    "    return df[final_mask]\n",
    "    \n",
    "dumb_find(query1).page.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4255d-c9f0-4182-bc26-95985fcda38f",
   "metadata": {},
   "source": [
    "apply the ranking method to the previous result to see the most likely prediction. \n",
    "\n",
    "display the top 10 result. Which is the predicted character for Ned? and for Queen Hand ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b9291d6-ffde-4354-bdf3-e0e65f08134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ned\n",
      "52 3669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Stannis_Baratheon',\n",
       " 'Joffrey_Baratheon',\n",
       " 'Eddard_Stark',\n",
       " 'Cersei_Lannister',\n",
       " 'Jaime_Lannister',\n",
       " 'Renly_Baratheon',\n",
       " 'Jon_Snow',\n",
       " 'Robert_I_Baratheon',\n",
       " 'Catelyn_Stark',\n",
       " 'Bran_Stark']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_these_pages(dumb_find(query1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c738543f-18fa-4e10-bb27-721d2612e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen\n",
      "695 3669\n",
      "hand\n",
      "594 3669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Stannis_Baratheon',\n",
       " 'Tyrion_Lannister',\n",
       " 'Robb_Stark',\n",
       " 'Joffrey_Baratheon',\n",
       " 'Tommen_Baratheon',\n",
       " 'Daenerys_Targaryen',\n",
       " 'Eddard_Stark',\n",
       " 'Cersei_Lannister',\n",
       " 'Jaime_Lannister',\n",
       " 'Tywin_Lannister']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_these_pages(dumb_find(query2).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b3abe8-d427-462a-84aa-0104928e0bdf",
   "metadata": {},
   "source": [
    "### 4.2 JACCARD Solution find \n",
    "\n",
    "the easy solution to compare the query and the text suppose different strategies. \n",
    "\n",
    "For jaccard, we want to build a score based on the difference between length of intersection of query set and text word set and the length of the union of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f907e91-889c-43fe-9a4b-04d07ec48548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stannis_Baratheon',\n",
       " 'Tyrion_Lannister',\n",
       " 'Robb_Stark',\n",
       " 'Joffrey_Baratheon',\n",
       " 'Tommen_Baratheon',\n",
       " 'Daenerys_Targaryen',\n",
       " 'Eddard_Stark',\n",
       " 'Cersei_Lannister',\n",
       " 'Jaime_Lannister',\n",
       " 'Tywin_Lannister']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(query):\n",
    "    query_set = set(query.split())\n",
    "    jaccard = df.bow.apply(lambda x: len(set(x).intersection(query_set)) / len(set(x).union(query_set)))\n",
    "    return df[jaccard > 0]\n",
    "\n",
    "rank_these_pages(jaccard(query2).index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06641ef-80ef-481a-bc5c-534acd0541a8",
   "metadata": {},
   "source": [
    "jaccard can also be used to rank but it is not the best at ranking since it is solely based on the size of sets. \n",
    "\n",
    "Another similar technique is w-shingling. w-shingling uses the exact same logic of intersection / union — but with ‘shingles’ also called 2-grams. A 2-gram is sequence of two word instead of a single word. Google has revealed a popular version of this using n-grams that you can try in [Google ngrams](https://books.google.com/ngrams/)\n",
    "\n",
    "We will skip this technique as it is only a matter of programming to use another technique called levenstein distance\n",
    "\n",
    "The [levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) measure the similarity between two string by measuring how many change are necessary to go from to the other. It is used to correct entries in search queries when user makes a typo. Lets try it with suggesting the most likely alternative to __'nud'__, a mispelling of __'ned'__. \n",
    "\n",
    "[Documentation Levenshtein](https://rapidfuzz.github.io/Levenshtein/levenshtein.html#distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd45c035-3514-4741-a230-7c126a9d07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0635e8a-7b75-4ec5-861c-da6704202a48",
   "metadata": {},
   "source": [
    "write a function most_likely_word that tries every single letter in ascii with nud, calculate the levenstein distance with each word in the bow, retrieve the minimum and sum the result for each text. \n",
    "\n",
    "The result need to be put in a dictionary containing key=word and value=sum of the min distance \n",
    "\n",
    "What is the most likely word similar to nud that would yield good result with our dataframe ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bef7e6a-502f-4cb1-9fbe-9212c3e4924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9360"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'nud'\n",
    "\n",
    "def most_likely_word(word):\n",
    "    result = {}\n",
    "    for i in range(len(word)):\n",
    "        for l in string.ascii_lowercase:\n",
    "            if word[i] != l:\n",
    "                new_word = list(word)\n",
    "                new_word[i] = l\n",
    "                new_word = ''.join(new_word)\n",
    "                leven = df.bow.apply(lambda x: min([Levenshtein.distance(w,new_word) for w in x]))\n",
    "                result[new_word] = sum(leven)\n",
    "    return result\n",
    "result = most_likely_word(word)\n",
    "result.get('iud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2663657-cffa-4b38-b4fb-69e8464e90e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ned', 7542), ('nod', 8268), ('nad', 8296), ('lud', 8325), ('oud', 8576)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(result.items(), key=lambda x: x[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93424304-d9a9-4376-b805-e80a8d52b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you probably mean \"ned\" instead of \"nud\"\n"
     ]
    }
   ],
   "source": [
    "print(f'you probably mean \"{sorted(result.items(), key=lambda x: x[1])[0][0]}\" instead of \"{word}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102353f-5900-469f-b574-2ee6b20cb11d",
   "metadata": {},
   "source": [
    "### 4.3 the vectorized Solution\n",
    "\n",
    "For vector-based search, we typically find one of several vector building methods:\n",
    "- TF-IDF\n",
    "- BM25\n",
    "- word2vec/doc2vec\n",
    "- BERT\n",
    "\n",
    "In tandem with some implementation of approximate nearest neighbors (ANN), these vector-based methods are the MVPs in the world of similarity search.\n",
    "\n",
    "We will start with a basic approach the count vectorizer. The count vectorizer is quite naive and convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7fc76ef-38b0-4cda-a19e-71fae1bb4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f0250-c9ba-48ee-981c-6a8496d4357e",
   "metadata": {},
   "source": [
    "#### 4.3.1 Count vectorizer\n",
    "\n",
    "We start with the count vectorizer. The count vectorizer count how many time each token or each word of the vocabulary appears in the text. \n",
    "\n",
    "There will be as many columns as there is unique word in the text.\n",
    "\n",
    "Therefore each document (each row if you will) will be a vector with length-of-the-vocabulary dimensions (big). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44e521a4-9522-434d-935c-70166bc614a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vocabulary is  ['aahooooooo' 'abandon' 'abandoned' ... 'zorse' 'zorseface' 'zorseriders']\n"
     ]
    }
   ],
   "source": [
    "# initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# initialize the vocabulary and the count and fit it with the text from the df\n",
    "doc_term_matrix = vectorizer.fit_transform(df.text)\n",
    "\n",
    "print('the vocabulary is ', vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f85ecc-8736-4fb7-af52-c02002a47840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the vocabulary is 22389\n"
     ]
    }
   ],
   "source": [
    "print('the length of the vocabulary is', doc_term_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240cbeb-7036-4227-a583-a88213dc8bf4",
   "metadata": {},
   "source": [
    "we transform the doc_term_matrix into a dataframe so you can take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86f6f8cd-5612-4e36-a017-5a26371f74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorizer = pd.DataFrame(\n",
    "   doc_term_matrix.todense(),\n",
    "   columns=vectorizer.get_feature_names_out(),\n",
    "   index=df.page\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e0f73ae-a80d-49b3-be2e-f1205ad99f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aahooooooo</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abdicated</th>\n",
       "      <th>...</th>\n",
       "      <th>zherzyn</th>\n",
       "      <th>zhoe</th>\n",
       "      <th>zia</th>\n",
       "      <th>zo</th>\n",
       "      <th>zollo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoqora</th>\n",
       "      <th>zorse</th>\n",
       "      <th>zorseface</th>\n",
       "      <th>zorseriders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Garth_the_Gardener</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nymor_Martell</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lyman_Lannister</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tommen_Costayne_(knight)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ernest_Dabell</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          aahooooooo  abandon  abandoned  abandoning  \\\n",
       "page                                                                   \n",
       "Garth_the_Gardener                 0        0          0           0   \n",
       "Nymor_Martell                      0        0          0           0   \n",
       "Lyman_Lannister                    0        0          1           0   \n",
       "Tommen_Costayne_(knight)           0        0          0           0   \n",
       "Ernest_Dabell                      0        0          0           0   \n",
       "\n",
       "                          abandonment  abandons  abate  abated  abdicate  \\\n",
       "page                                                                       \n",
       "Garth_the_Gardener                  0         0      0       0         0   \n",
       "Nymor_Martell                       0         0      0       0         0   \n",
       "Lyman_Lannister                     0         0      0       0         0   \n",
       "Tommen_Costayne_(knight)            0         0      0       0         0   \n",
       "Ernest_Dabell                       0         0      0       0         0   \n",
       "\n",
       "                          abdicated  ...  zherzyn  zhoe  zia  zo  zollo  zone  \\\n",
       "page                                 ...                                        \n",
       "Garth_the_Gardener                0  ...        0     0    0   0      0     0   \n",
       "Nymor_Martell                     0  ...        0     0    0   0      0     0   \n",
       "Lyman_Lannister                   0  ...        0     0    0   0      0     0   \n",
       "Tommen_Costayne_(knight)          0  ...        0     0    0   0      0     0   \n",
       "Ernest_Dabell                     0  ...        0     0    0   0      0     0   \n",
       "\n",
       "                          zoqora  zorse  zorseface  zorseriders  \n",
       "page                                                             \n",
       "Garth_the_Gardener             0      0          0            0  \n",
       "Nymor_Martell                  0      0          0            0  \n",
       "Lyman_Lannister                0      0          0            0  \n",
       "Tommen_Costayne_(knight)       0      0          0            0  \n",
       "Ernest_Dabell                  0      0          0            0  \n",
       "\n",
       "[5 rows x 22389 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorizer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405d295-1cc4-46dc-b0fb-b055d2966a1d",
   "metadata": {},
   "source": [
    "Now to query the dataset, we simply need to _transform our query in a similar vector object_ with the same vocabulary, hence the same columns, using the __transform__ function of the __vectorizer__ model and not the fit_transform!\n",
    "\n",
    "We obtain a vector that we will compare to other vectors or documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b239ba9-4088-4f75-99a8-911f6e0ed868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ned'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73b69ec9-5b24-40eb-9cc8-7aa5e039028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = vectorizer.transform([query1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b13004ce-94fe-42f4-b827-b7536e64dc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x22389 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b53ebc-615b-468c-9bb7-c3105abca1ae",
   "metadata": {},
   "source": [
    "Once we have the query vector, we can calculate the distance between this vector and each document vector to find the most likely document in the list, the one where the vector are more similar.\n",
    "\n",
    "For that we use the [__cosine similarity__](https://en.wikipedia.org/wiki/Cosine_similarity). Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space based on the cosine of the angle between them, resulting in a value between -1 and 1. The value -1 means that the vectors are opposite, 0 represents orthogonal vectors, and value 1 signifies similar vectors.\n",
    "\n",
    "We use the [sklearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#examples-using-sklearn-metrics-pairwise-cosine-similarity) and reshape it to be just one dimensional with all the similarity scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd2b036c-7347-48c4-b4b7-1091fb782e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosim = cosine_similarity(doc_term_matrix, query_vec).reshape(3669,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfd612-4124-43f7-8a4c-7a36ea8e8869",
   "metadata": {},
   "source": [
    "Now we can retrieve the top 10 vector with the highest scores. We get an index list so it can be used directly in the ranking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e96d637-cdd9-43bc-83a9-61918d7240e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eddard_Stark',\n",
       " 'Jory_Cassel',\n",
       " 'Godric_Borrell',\n",
       " 'Edric_Dayne',\n",
       " 'Willam_Dustin',\n",
       " 'Ned_Bean',\n",
       " 'Humfrey_Clifton',\n",
       " 'Ned_Woods',\n",
       " 'Porther',\n",
       " 'Ned_(ferryman)']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_similar_to_query = np.argsort(cosim)[-10:]\n",
    "rank_these_pages(top10_similar_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a1e70b8-deef-4195-9ff5-c4a1e46c0457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>title</th>\n",
       "      <th>infobox_name</th>\n",
       "      <th>infobox</th>\n",
       "      <th>aliases_names</th>\n",
       "      <th>text_length</th>\n",
       "      <th>books</th>\n",
       "      <th>text</th>\n",
       "      <th>links</th>\n",
       "      <th>infobox_length</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweeness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>minkowski</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>Humfrey_Clifton</td>\n",
       "      <td>Humfrey Clifton</td>\n",
       "      <td>Humfrey Clifton</td>\n",
       "      <td>{'allegiances': 'House Clifton\n",
       "House Baratheon...</td>\n",
       "      <td>[]</td>\n",
       "      <td>615</td>\n",
       "      <td>{'A Dance with Dragons': 'appears'}</td>\n",
       "      <td>humfrey clifton knight house clifton sworn swo...</td>\n",
       "      <td>[Stannis_Baratheon, Ned_Woods, Gareth_Clifton]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.248314</td>\n",
       "      <td>0.248314</td>\n",
       "      <td>0.248314</td>\n",
       "      <td>[humfrey, clifton, knight, house, clifton, swo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>Jory_Cassel</td>\n",
       "      <td>Jory Cassel</td>\n",
       "      <td>Jory Cassel</td>\n",
       "      <td>{'allegiances': 'House Cassel\n",
       "House Stark', 'c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5186</td>\n",
       "      <td>{'A Game of Thrones': 'appears', 'A Clash of K...</td>\n",
       "      <td>jory cassel house cassel captain household gua...</td>\n",
       "      <td>[Tyrion_Lannister, Beth_Cassel, Gared, Rodrik_...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.330794</td>\n",
       "      <td>0.330794</td>\n",
       "      <td>0.330794</td>\n",
       "      <td>[jory, cassel, house, cassel, captain, househo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>Godric_Borrell</td>\n",
       "      <td>Godric Borrell</td>\n",
       "      <td>Godric Borrell</td>\n",
       "      <td>{'titles': ['Lord of Sweetsister', 'Shield of ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3355</td>\n",
       "      <td>{'A Feast for Crows': 'appendix', 'A Dance wit...</td>\n",
       "      <td>godric borrell lord sweetsister shield sistert...</td>\n",
       "      <td>[Wyman_Manderly, Tywin_Lannister, Lord_Borrell...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.321301</td>\n",
       "      <td>0.321301</td>\n",
       "      <td>0.321301</td>\n",
       "      <td>[godric, borrell, lord, sweetsister, shield, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>Porther</td>\n",
       "      <td>Porther</td>\n",
       "      <td>Porther</td>\n",
       "      <td>{'allegiance': 'House Stark', 'culture': 'Nort...</td>\n",
       "      <td>[]</td>\n",
       "      <td>348</td>\n",
       "      <td>{'A Game of Thrones': 'appears', 'A Clash of K...</td>\n",
       "      <td>porther household guard lord eddard stark wint...</td>\n",
       "      <td>[Bran_Stark, Eddard_Stark]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>[porther, household, guard, lord, eddard, star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>Willam_Dustin</td>\n",
       "      <td>Willam Dustin</td>\n",
       "      <td>Willam Dustin</td>\n",
       "      <td>{'allegiance': 'House Dustin', 'successor': 'B...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1983</td>\n",
       "      <td>{'A Game of Thrones': 'mentioned', 'A Feast fo...</td>\n",
       "      <td>willam dustin lord barrowton head house dustin...</td>\n",
       "      <td>[Barbrey_Dustin, Theon_Greyjoy, Catelyn_Stark,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.304846</td>\n",
       "      <td>0.304846</td>\n",
       "      <td>0.304846</td>\n",
       "      <td>[willam, dustin, lord, barrowton, head, house,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Eddard_Stark</td>\n",
       "      <td>Eddard Stark</td>\n",
       "      <td>Eddard Stark</td>\n",
       "      <td>{'aliases': ['ned', 'the quiet wolf', 'the ned...</td>\n",
       "      <td>[ned, the quiet wolf, the ned]</td>\n",
       "      <td>25094</td>\n",
       "      <td>{'The World of Ice &amp; Fire': 'mentioned', 'A Ga...</td>\n",
       "      <td>eddard stark called ned head house stark lord ...</td>\n",
       "      <td>[Elia_Martell, Brandon_Stark, Kevan_Lannister,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.447051</td>\n",
       "      <td>0.447108</td>\n",
       "      <td>0.447108</td>\n",
       "      <td>[eddard, stark, called, ned, head, house, star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Edric_Dayne</td>\n",
       "      <td>Edric Dayne</td>\n",
       "      <td>Edric Dayne</td>\n",
       "      <td>{'allegiances': 'House Dayne\n",
       "brotherhood witho...</td>\n",
       "      <td>[ned]</td>\n",
       "      <td>4570</td>\n",
       "      <td>{'A Game of Thrones': 'appendix', 'A Clash of ...</td>\n",
       "      <td>edric dayne ned lord starfall head house dayne...</td>\n",
       "      <td>[Sandor_Clegane, Ashara_Dayne, Loras_Tyrell, A...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.316675</td>\n",
       "      <td>0.316675</td>\n",
       "      <td>0.316675</td>\n",
       "      <td>[edric, dayne, ned, lord, starfall, head, hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>Ned_(ferryman)</td>\n",
       "      <td>Ned (ferryman)</td>\n",
       "      <td>Ned</td>\n",
       "      <td>{'culture': 'Rivermen', 'books': {'The Mystery...</td>\n",
       "      <td>[]</td>\n",
       "      <td>366</td>\n",
       "      <td>{'The Mystery Knight': 'appears'}</td>\n",
       "      <td>ned ferryman inn lakeshore whitewalls reign ki...</td>\n",
       "      <td>[Lord_Shawney, Lord_Costayne_(Aerys_I), Aerys_...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>[ned, ferryman, inn, lakeshore, whitewalls, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>Ned_Bean</td>\n",
       "      <td>Ned Bean</td>\n",
       "      <td>Ned Bean</td>\n",
       "      <td>{'allegiance': 'House Targaryen', 'books': {'F...</td>\n",
       "      <td>[blackbean]</td>\n",
       "      <td>1143</td>\n",
       "      <td>{'Fire &amp; Blood': 'mentioned', 'The Rise of the...</td>\n",
       "      <td>ned bean called blackbean notorious sellsail s...</td>\n",
       "      <td>[Gedmund_Peake, Unwin_Peake, Aegon_III_Targary...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.250967</td>\n",
       "      <td>0.250967</td>\n",
       "      <td>0.250967</td>\n",
       "      <td>[ned, bean, called, blackbean, notorious, sell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>Ned_Woods</td>\n",
       "      <td>Ned Woods</td>\n",
       "      <td>Ned Woods</td>\n",
       "      <td>{'allegiance': 'House Woods', 'culture': 'Nort...</td>\n",
       "      <td>[noseless ned]</td>\n",
       "      <td>328</td>\n",
       "      <td>{'A Dance with Dragons': 'appears'}</td>\n",
       "      <td>ned woods noseless ned house woods wolfswood s...</td>\n",
       "      <td>[Stannis_Baratheon, Sybelle_Glover]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.196714</td>\n",
       "      <td>0.196714</td>\n",
       "      <td>0.196714</td>\n",
       "      <td>[ned, woods, noseless, ned, house, woods, wolf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 page            title     infobox_name  \\\n",
       "2909  Humfrey_Clifton  Humfrey Clifton  Humfrey Clifton   \n",
       "1146      Jory_Cassel      Jory Cassel      Jory Cassel   \n",
       "3636   Godric_Borrell   Godric Borrell   Godric Borrell   \n",
       "2922          Porther          Porther          Porther   \n",
       "1115    Willam_Dustin    Willam Dustin    Willam Dustin   \n",
       "174      Eddard_Stark     Eddard Stark     Eddard Stark   \n",
       "402       Edric_Dayne      Edric Dayne      Edric Dayne   \n",
       "2388   Ned_(ferryman)   Ned (ferryman)              Ned   \n",
       "3290         Ned_Bean         Ned Bean         Ned Bean   \n",
       "2482        Ned_Woods        Ned Woods        Ned Woods   \n",
       "\n",
       "                                                infobox  \\\n",
       "2909  {'allegiances': 'House Clifton\n",
       "House Baratheon...   \n",
       "1146  {'allegiances': 'House Cassel\n",
       "House Stark', 'c...   \n",
       "3636  {'titles': ['Lord of Sweetsister', 'Shield of ...   \n",
       "2922  {'allegiance': 'House Stark', 'culture': 'Nort...   \n",
       "1115  {'allegiance': 'House Dustin', 'successor': 'B...   \n",
       "174   {'aliases': ['ned', 'the quiet wolf', 'the ned...   \n",
       "402   {'allegiances': 'House Dayne\n",
       "brotherhood witho...   \n",
       "2388  {'culture': 'Rivermen', 'books': {'The Mystery...   \n",
       "3290  {'allegiance': 'House Targaryen', 'books': {'F...   \n",
       "2482  {'allegiance': 'House Woods', 'culture': 'Nort...   \n",
       "\n",
       "                       aliases_names  text_length  \\\n",
       "2909                              []          615   \n",
       "1146                              []         5186   \n",
       "3636                              []         3355   \n",
       "2922                              []          348   \n",
       "1115                              []         1983   \n",
       "174   [ned, the quiet wolf, the ned]        25094   \n",
       "402                            [ned]         4570   \n",
       "2388                              []          366   \n",
       "3290                     [blackbean]         1143   \n",
       "2482                  [noseless ned]          328   \n",
       "\n",
       "                                                  books  \\\n",
       "2909                {'A Dance with Dragons': 'appears'}   \n",
       "1146  {'A Game of Thrones': 'appears', 'A Clash of K...   \n",
       "3636  {'A Feast for Crows': 'appendix', 'A Dance wit...   \n",
       "2922  {'A Game of Thrones': 'appears', 'A Clash of K...   \n",
       "1115  {'A Game of Thrones': 'mentioned', 'A Feast fo...   \n",
       "174   {'The World of Ice & Fire': 'mentioned', 'A Ga...   \n",
       "402   {'A Game of Thrones': 'appendix', 'A Clash of ...   \n",
       "2388                  {'The Mystery Knight': 'appears'}   \n",
       "3290  {'Fire & Blood': 'mentioned', 'The Rise of the...   \n",
       "2482                {'A Dance with Dragons': 'appears'}   \n",
       "\n",
       "                                                   text  \\\n",
       "2909  humfrey clifton knight house clifton sworn swo...   \n",
       "1146  jory cassel house cassel captain household gua...   \n",
       "3636  godric borrell lord sweetsister shield sistert...   \n",
       "2922  porther household guard lord eddard stark wint...   \n",
       "1115  willam dustin lord barrowton head house dustin...   \n",
       "174   eddard stark called ned head house stark lord ...   \n",
       "402   edric dayne ned lord starfall head house dayne...   \n",
       "2388  ned ferryman inn lakeshore whitewalls reign ki...   \n",
       "3290  ned bean called blackbean notorious sellsail s...   \n",
       "2482  ned woods noseless ned house woods wolfswood s...   \n",
       "\n",
       "                                                  links  infobox_length  \\\n",
       "2909     [Stannis_Baratheon, Ned_Woods, Gareth_Clifton]               5   \n",
       "1146  [Tyrion_Lannister, Beth_Cassel, Gared, Rodrik_...              10   \n",
       "3636  [Wyman_Manderly, Tywin_Lannister, Lord_Borrell...               8   \n",
       "2922                         [Bran_Stark, Eddard_Stark]               5   \n",
       "1115  [Barbrey_Dustin, Theon_Greyjoy, Catelyn_Stark,...               8   \n",
       "174   [Elia_Martell, Brandon_Stark, Kevan_Lannister,...              16   \n",
       "402   [Sandor_Clegane, Ashara_Dayne, Loras_Tyrell, A...               6   \n",
       "2388  [Lord_Shawney, Lord_Costayne_(Aerys_I), Aerys_...               3   \n",
       "3290  [Gedmund_Peake, Unwin_Peake, Aegon_III_Targary...               4   \n",
       "2482                [Stannis_Baratheon, Sybelle_Glover]               4   \n",
       "\n",
       "      pagerank  betweeness  closeness  euclidean  minkowski  \\\n",
       "2909  0.000059    0.000059   0.248314   0.248314   0.248314   \n",
       "1146  0.000373    0.000373   0.330794   0.330794   0.330794   \n",
       "3636  0.000228    0.000228   0.321301   0.321301   0.321301   \n",
       "2922  0.000044    0.000044   0.000000   0.000062   0.000062   \n",
       "1115  0.000163    0.000163   0.304846   0.304846   0.304846   \n",
       "174   0.005050    0.005050   0.447051   0.447108   0.447108   \n",
       "402   0.000224    0.000224   0.316675   0.316675   0.316675   \n",
       "2388  0.000044    0.000044   0.000000   0.000062   0.000062   \n",
       "3290  0.000080    0.000080   0.250967   0.250967   0.250967   \n",
       "2482  0.000061    0.000061   0.196714   0.196714   0.196714   \n",
       "\n",
       "                                                    bow  \n",
       "2909  [humfrey, clifton, knight, house, clifton, swo...  \n",
       "1146  [jory, cassel, house, cassel, captain, househo...  \n",
       "3636  [godric, borrell, lord, sweetsister, shield, s...  \n",
       "2922  [porther, household, guard, lord, eddard, star...  \n",
       "1115  [willam, dustin, lord, barrowton, head, house,...  \n",
       "174   [eddard, stark, called, ned, head, house, star...  \n",
       "402   [edric, dayne, ned, lord, starfall, head, hous...  \n",
       "2388  [ned, ferryman, inn, lakeshore, whitewalls, re...  \n",
       "3290  [ned, bean, called, blackbean, notorious, sell...  \n",
       "2482  [ned, woods, noseless, ned, house, woods, wolf...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[top10_similar_to_query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc5f5a-7940-4bca-a19c-6ba68c0d8beb",
   "metadata": {},
   "source": [
    "#### 4.3.2 TFIDF vectorizer\n",
    "\n",
    "TF-IDF consists of two parts, Term Frequency (TF) and Inverse Document Frequency (IDF).\n",
    "\n",
    "The TF component counts the number of times a term appears within a document and divides this by the total number of terms in that same document.\n",
    "\n",
    "The Term Frequency is a good measure, but doesn’t allow us to differentiate between common and uncommon words. If we were to search for the word ‘the’ — using TF alone we’d assign this sentence the same relevance as had we searched ‘bananas’.\n",
    "\n",
    "That’s fine until we begin comparing documents, or searching with longer queries. We don’t want words like ‘the’,_ ‘is’_, or _‘it’_ to be ranked as highly as _‘bananas’_ or _‘street’_.\n",
    "\n",
    "Ideally, we want matches between rarer words to score higher. To do this, we can multiply TF by the second term — IDF. The Inverse Document Frequency measures how common a word is across all of our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b4ed1cc-6e02-426b-9614-62572c6e889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vocabulary is  ['aahooooooo' 'abandon' 'abandoned' ... 'zorse' 'zorseface' 'zorseriders']\n",
      "the length of the vocabulary is 22389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aahooooooo</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abdicated</th>\n",
       "      <th>...</th>\n",
       "      <th>zherzyn</th>\n",
       "      <th>zhoe</th>\n",
       "      <th>zia</th>\n",
       "      <th>zo</th>\n",
       "      <th>zollo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoqora</th>\n",
       "      <th>zorse</th>\n",
       "      <th>zorseface</th>\n",
       "      <th>zorseriders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Garth_the_Gardener</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nymor_Martell</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lyman_Lannister</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tommen_Costayne_(knight)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ernest_Dabell</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          aahooooooo  abandon  abandoned  abandoning  \\\n",
       "page                                                                   \n",
       "Garth_the_Gardener               0.0      0.0   0.000000         0.0   \n",
       "Nymor_Martell                    0.0      0.0   0.000000         0.0   \n",
       "Lyman_Lannister                  0.0      0.0   0.024355         0.0   \n",
       "Tommen_Costayne_(knight)         0.0      0.0   0.000000         0.0   \n",
       "Ernest_Dabell                    0.0      0.0   0.000000         0.0   \n",
       "\n",
       "                          abandonment  abandons  abate  abated  abdicate  \\\n",
       "page                                                                       \n",
       "Garth_the_Gardener                0.0       0.0    0.0     0.0       0.0   \n",
       "Nymor_Martell                     0.0       0.0    0.0     0.0       0.0   \n",
       "Lyman_Lannister                   0.0       0.0    0.0     0.0       0.0   \n",
       "Tommen_Costayne_(knight)          0.0       0.0    0.0     0.0       0.0   \n",
       "Ernest_Dabell                     0.0       0.0    0.0     0.0       0.0   \n",
       "\n",
       "                          abdicated  ...  zherzyn  zhoe  zia   zo  zollo  \\\n",
       "page                                 ...                                   \n",
       "Garth_the_Gardener              0.0  ...      0.0   0.0  0.0  0.0    0.0   \n",
       "Nymor_Martell                   0.0  ...      0.0   0.0  0.0  0.0    0.0   \n",
       "Lyman_Lannister                 0.0  ...      0.0   0.0  0.0  0.0    0.0   \n",
       "Tommen_Costayne_(knight)        0.0  ...      0.0   0.0  0.0  0.0    0.0   \n",
       "Ernest_Dabell                   0.0  ...      0.0   0.0  0.0  0.0    0.0   \n",
       "\n",
       "                          zone  zoqora  zorse  zorseface  zorseriders  \n",
       "page                                                                   \n",
       "Garth_the_Gardener         0.0     0.0    0.0        0.0          0.0  \n",
       "Nymor_Martell              0.0     0.0    0.0        0.0          0.0  \n",
       "Lyman_Lannister            0.0     0.0    0.0        0.0          0.0  \n",
       "Tommen_Costayne_(knight)   0.0     0.0    0.0        0.0          0.0  \n",
       "Ernest_Dabell              0.0     0.0    0.0        0.0          0.0  \n",
       "\n",
       "[5 rows x 22389 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# initialize the vocabulary and the count and fit it with the text from the df\n",
    "doc_term_matrix = vectorizer.fit_transform(df.text)\n",
    "\n",
    "print('the vocabulary is ', vectorizer.get_feature_names_out())\n",
    "\n",
    "print('the length of the vocabulary is', doc_term_matrix.shape[1])\n",
    "\n",
    "df_vectorizer = pd.DataFrame(\n",
    "   doc_term_matrix.todense(),\n",
    "   columns=vectorizer.get_feature_names_out(),\n",
    "   index=df.page\n",
    ")\n",
    "\n",
    "df_vectorizer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc569c11-144a-49f4-922a-a32f8891ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tyrion_Lannister',\n",
       " 'Shae',\n",
       " 'Tysha',\n",
       " 'Penny',\n",
       " 'Symon_Silver_Tongue',\n",
       " 'Jyck',\n",
       " 'Tyrion_III_Lannister',\n",
       " 'Tyrion_II_Lannister',\n",
       " 'Cerenna_Lannister',\n",
       " 'Myrielle_Lannister']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Tyrion lannister'\n",
    "qvectors = []\n",
    "for q in query.split(): \n",
    "    qvector = vectorizer.transform([q])\n",
    "    qvectors.append(qvector.todense())\n",
    "\n",
    "qvector_mean = np.mean(qvectors, axis=0)\n",
    "cosim = cosine_similarity(doc_term_matrix, qvector_mean).reshape(3669,)\n",
    "top10_similar_to_query = np.argsort(cosim)[-10:]\n",
    "rank_these_pages(top10_similar_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3651e906-3e44-49fe-9e7a-0a964dd30a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.02797729, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5eb52-b216-4ef9-b835-b8c77abfba1b",
   "metadata": {},
   "source": [
    "#### 4.3.3 Word2vec, Doc2vec\n",
    "\n",
    "word2vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets. Embeddings learned through word2vec have proven to be successful on a variety of downstream natural language processing tasks:\n",
    "- ref [gensim word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "- ref [tensoflow word2vec](https://www.tensorflow.org/text/tutorials/word2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3e22db2-48b0-4a9f-af16-14110b784e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea30fa1-dff1-423e-87d4-ece049d1d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CBOW model\n",
    "model1 = gensim.models.Word2Vec(df.bow, min_count = 1, \n",
    "                              vector_size = 100, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2314d530-691a-43b9-a551-1cb696569d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'queen' and 'hand' - CBOW :  0.57926357\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Cosine similarity between 'queen' and 'hand' - CBOW : \",\n",
    "      model1.wv.similarity('queen', 'hand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91203bf1-b415-4746-bf38-a47fdc2ca9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Skip Gram model\n",
    "model2 = gensim.models.Word2Vec(df.bow, min_count = 1, vector_size = 100,\n",
    "                                             window = 5, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a2fd8eb-5255-4432-89c6-d32cbe4b2336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'queen' and 'hand' - CBOW :  0.21280481\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Cosine similarity between 'queen' and 'hand' - CBOW : \",\n",
    "    model2.wv.similarity('queen', 'hand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e3d8c2f-e50a-47e1-a9d9-e8f8c21106a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.77107298e-01,  1.99746504e-01, -4.22578044e-02, -2.81017095e-01,\n",
       "        3.00629526e-01, -3.83131713e-01,  2.63958097e-01,  4.58949834e-01,\n",
       "       -4.23339568e-02, -4.61202979e-01,  9.16755106e-03, -5.58270991e-01,\n",
       "       -1.22624755e-01, -2.09035009e-01,  4.43659484e-01,  3.75547782e-02,\n",
       "       -5.07404171e-02,  1.74354643e-01,  1.10094018e-01, -4.53469813e-01,\n",
       "        4.14801925e-01, -3.35903943e-01, -4.58152771e-01,  1.40801342e-02,\n",
       "       -4.21119750e-01,  3.79248828e-01, -5.46472669e-01, -3.16807926e-01,\n",
       "       -1.56888086e-02, -5.84754981e-02,  1.63402408e-01,  6.11822456e-02,\n",
       "       -1.37414597e-03, -4.57556337e-01,  3.33591431e-01, -2.01587498e-01,\n",
       "        4.04244661e-01, -2.52163976e-01, -3.63813564e-02, -3.67035091e-01,\n",
       "       -2.84338057e-01, -3.17353815e-01, -3.23182434e-01, -3.64508450e-01,\n",
       "       -3.98589224e-01, -3.21976990e-01, -4.72514063e-01,  6.58583418e-02,\n",
       "        1.14823021e-01,  2.98412174e-01, -1.08382897e-02, -4.47700918e-01,\n",
       "        6.65694103e-02,  3.46101858e-02,  2.75585413e-01, -9.08179767e-03,\n",
       "        5.19521773e-01,  6.55152788e-03,  6.07543997e-02,  6.11059591e-02,\n",
       "        1.65540189e-01,  1.87062636e-01,  8.46204460e-02, -2.08054826e-01,\n",
       "       -3.59626502e-01,  1.18174575e-01,  2.57689655e-01, -1.92204148e-01,\n",
       "       -8.04215744e-02, -2.56750524e-01, -4.77933735e-02,  1.57213524e-01,\n",
       "       -3.58538404e-02,  1.08352281e-01,  1.60112083e-01,  8.20060596e-02,\n",
       "        7.36638382e-02,  1.73547044e-01, -4.76779729e-01,  1.26222745e-01,\n",
       "       -3.90786171e-01,  2.26463720e-01,  2.19392583e-01,  3.95974755e-01,\n",
       "       -8.27178597e-01,  2.27597907e-01, -3.08486909e-01, -1.11991726e-01,\n",
       "        1.09051727e-01, -6.21239742e-05,  2.02797696e-01,  1.19527668e-01,\n",
       "       -2.37531066e-02, -1.30951747e-01,  4.40936722e-02,  3.96991670e-01,\n",
       "       -3.04556727e-01, -3.56040001e-01, -4.93016541e-01,  3.50593865e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.get_vector('ned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96a42db8-661a-4b95-a3e1-346e7dd23eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word2vec'] = df.bow.apply(model2.wv.get_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d542f1b1-3867-482b-9fc7-33940ec0a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aemond_Targaryen',\n",
       " 'Addam_Velaryon',\n",
       " 'Nettles',\n",
       " 'Loreth_Lansdale',\n",
       " 'Robin_(Flea_Bottom)',\n",
       " 'Dhako',\n",
       " 'Elinda_Massey',\n",
       " 'Byron_Swann',\n",
       " 'Bean',\n",
       " 'Jaenara_Belaerys']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1v = model2.wv.get_mean_vector(\"dragon\".split()) \n",
    "\n",
    "cosim = df.word2vec.apply(lambda x: cosine_similarity([x], [q1v]))\n",
    "\n",
    "top10_similar_to_query = np.argsort(cosim)[-10:]\n",
    "rank_these_pages(top10_similar_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b45dca9-f76b-415b-bb13-f646bba2de54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jaime_Lannister',\n",
       " 'Ilyn_Payne',\n",
       " 'Boros_Blount',\n",
       " 'Tion_Frey',\n",
       " 'Lewys_Piper',\n",
       " 'Josmyn_Peckledon',\n",
       " 'Emmon_Cuy',\n",
       " 'Lyle_Crakehall',\n",
       " 'Enger',\n",
       " 'Hoke']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1v = model2.wv.get_mean_vector(\"kingslayer\".split()) \n",
    "\n",
    "cosim = df.word2vec.apply(lambda x: cosine_similarity([x], [q1v]))\n",
    "\n",
    "top10_similar_to_query = np.argsort(cosim)[-10:]\n",
    "rank_these_pages(top10_similar_to_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f07f1-67ba-441a-9c1a-596385ae5b3c",
   "metadata": {},
   "source": [
    "With the Word2Vec model, we can calculate the vectors for each word in a document. But what if we want to calculate a vector for the entire document? We could average the vectors for each word in the document - while this is quick and crude, it can often be useful. However, there is a better way…\n",
    "\n",
    "Introducing: Paragraph Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0982c3d-e0ac-4b64-8c57-7ee150f6478f",
   "metadata": {},
   "source": [
    "## 5 Assemble everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38ef533f-3ff4-40b2-bcca-451512145072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({374, 498, 576, 696, 1227, 1547, 1688, 2246, 3560, 3664},\n",
       " {374, 498, 576, 696, 1227, 1547, 1688, 2246, 3560, 3664},\n",
       " set(),\n",
       " {374, 498, 576, 696, 1227, 1547, 1688, 2246, 3560, 3664})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_corpus(query, book):\n",
    "    q = query.lower().split()\n",
    "    \n",
    "    # limit the corpus only to books where the search is supposed to occur\n",
    "    mask_book = df.books.apply(lambda x: np.any([book.lower() == k.lower() for k in x.keys()]))\n",
    "    corpus = df.loc[mask_book]\n",
    "    i_corpus = set(corpus.index)\n",
    "    \n",
    "    # query in main title\n",
    "    mask_title = corpus.title.apply(lambda x: set(q).issubset(set(x.lower().split())))\n",
    "    i_main_title = set(corpus[mask_title].index)\n",
    "    \n",
    "    # query in infobox name\n",
    "    mask_infobox_name = corpus.infobox_name.apply(lambda x: set(q).issubset(set(x.lower().split())))\n",
    "    i_infobox_name = set(corpus[mask_infobox_name].index)\n",
    "    \n",
    "    # query in aliases \n",
    "    mask_aliases = corpus.aliases_names.apply(lambda x: np.any([set(q).issubset(set(a.lower().split())) for a in x]))\n",
    "    i_aliases = set(corpus[mask_aliases].index)\n",
    "    i_aliases\n",
    "    \n",
    "    # top 20 in text with tdf-idf vectorizer\n",
    "    qvectors = []\n",
    "    for q in query.lower().split(): \n",
    "        qvector = vectorizer.transform([q])\n",
    "        qvectors.append(qvector.todense())\n",
    "    qvector_mean = np.mean(qvectors, axis=0)\n",
    "    \n",
    "    cosim = cosine_similarity(doc_term_matrix, qvector_mean).reshape(3669,)\n",
    "    top20 = np.argsort(cosim)[-20:]\n",
    "    i_top20 = set(top20).intersection(i_corpus)\n",
    "    i_top20\n",
    "    \n",
    "    # assemble all\n",
    "    return (i_main_title,\n",
    "            i_infobox_name,\n",
    "            i_aliases,\n",
    "            i_main_title.union(i_infobox_name).union(i_aliases).union(i_top20))\n",
    "\n",
    "get_corpus('blackwood','a dance with dragons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f20cbebb-53cc-4a35-91a5-86e585c205ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>title_name</th>\n",
       "      <th>infobox_name</th>\n",
       "      <th>aliases</th>\n",
       "      <th>role</th>\n",
       "      <th>network_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Rodrik Stark (son of Beron)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.341693</td>\n",
       "      <td>0.289185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         character  title_name  infobox_name  aliases  role  \\\n",
       "index                                                                         \n",
       "488    Rodrik Stark (son of Beron)           0             0        0   0.5   \n",
       "\n",
       "       network_score      rank  \n",
       "index                           \n",
       "488         0.341693  0.289185  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict(corpus, book):\n",
    "    i_main_title, i_infobox_name, i_aliases, full_i  = corpus\n",
    "    \n",
    "    role_score = {'None':0, 'appendix':0.25, 'mentioned':0.5, 'appears':0.75, 'pov':1}\n",
    "\n",
    "    corpus_scores = []\n",
    "    for i in full_i:\n",
    "        role = {k.lower():v.lower() for k,v  in df.at[i,'books'].items()}.get(book,'None')\n",
    "        network_score = df.at[i,'euclidean']\n",
    "        \n",
    "        score = {\n",
    "            'index': i,\n",
    "            'character': df.at[i,'title'],\n",
    "            'title_name': 1 if i in i_main_title else 0,\n",
    "            'infobox_name': 1 if i in i_infobox_name else 0,\n",
    "            'aliases': 1 if i in i_aliases else 0,\n",
    "            'role': role_score.get(role),\n",
    "            'network_score': network_score\n",
    "        }\n",
    "        corpus_scores.append(score)\n",
    "    # print(corpus_scores)\n",
    "    if corpus_scores:\n",
    "        score_df = pd.DataFrame.from_records(corpus_scores,index='index')\n",
    "        score_df['rank'] = np.max([score_df.title_name, score_df.infobox_name], axis=0) * 0.1 + \\\n",
    "                        score_df.aliases * 0.1 + \\\n",
    "                        score_df.role * 0.1 + \\\n",
    "                        score_df.network_score * 0.7\n",
    "        return score_df.sort_values(by='rank',ascending=False)\n",
    "    else:\n",
    "        return pd.DataFrame([])\n",
    "\n",
    "predict(get_corpus('Lady Stark','a dance with dragons'),'a dance with dragons')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c3c924-3cbd-4aed-9954-541d62be4601",
   "metadata": {},
   "source": [
    "To use this on our text, we need \n",
    "DF\n",
    "vectorizer model\n",
    "doc_term_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8369c2e-bf63-4a03-9db7-fb6b741c4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.read_pickle('GOT-NER.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08dff124-c374-4d60-95a4-48b1e1ca167c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>persons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue</td>\n",
       "      <td>\"We should start back,\" Gared urged as the woo...</td>\n",
       "      <td>[Waymar Royce, Gared, Wall, Royce, Ser Waymar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bran</td>\n",
       "      <td>The morning had dawned clear and cold, with a ...</td>\n",
       "      <td>[B, Jon, Old Nan, Mance Rayder, Bran, Robb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Catelyn</td>\n",
       "      <td>Catelyn had never liked this godswood.\\n\\tShe ...</td>\n",
       "      <td>[At, Catelyn, Ned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Daenerys</td>\n",
       "      <td>Her brother held the gown up for her inspectio...</td>\n",
       "      <td>[Illyrio, Dany, Her, Drogo, Viserys, Khal, Be]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Eddard</td>\n",
       "      <td>The visitors poured through the castle gates i...</td>\n",
       "      <td>[Jaime Lannister, Tyrion Lannister, Ser, Rober...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>5</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Let them die,\" said Queen Selyse.\\n\\tIt was th...</td>\n",
       "      <td>[Ser Narbert, Devan Seaworth, Ser Brus, Ser Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>5</td>\n",
       "      <td>Trueborn Lord Of Winterfell.</td>\n",
       "      <td>\"Snow?\" said Tormund Giantsbane. \"You look lik...</td>\n",
       "      <td>[Melisandre, Mance, Jon Snow, Jon, Tormund Gia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>5</td>\n",
       "      <td>The Queen'S Hand</td>\n",
       "      <td>The Dornish prince was three days dying.\\n\\tHe...</td>\n",
       "      <td>[Ser Barristan Selmy, Quentyn Martell, Ser, Rh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>5</td>\n",
       "      <td>Daenerys</td>\n",
       "      <td>The hill was a stony island in a sea of green....</td>\n",
       "      <td>[She, Dany, Daenerys, Drogon, Bay, Valyria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>5</td>\n",
       "      <td>Epilogue</td>\n",
       "      <td>I am no traitor,\" the Knight of Griffin's Roos...</td>\n",
       "      <td>[Kevan, Ser, Esco, Margaery, Mace, Aerys, Tyre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     book                         title  \\\n",
       "0       1                      Prologue   \n",
       "1       1                          Bran   \n",
       "2       1                       Catelyn   \n",
       "3       1                      Daenerys   \n",
       "4       1                        Eddard   \n",
       "..    ...                           ...   \n",
       "340     5                           Jon   \n",
       "341     5  Trueborn Lord Of Winterfell.   \n",
       "342     5              The Queen'S Hand   \n",
       "343     5                      Daenerys   \n",
       "344     5                      Epilogue   \n",
       "\n",
       "                                                  text  \\\n",
       "0    \"We should start back,\" Gared urged as the woo...   \n",
       "1    The morning had dawned clear and cold, with a ...   \n",
       "2    Catelyn had never liked this godswood.\\n\\tShe ...   \n",
       "3    Her brother held the gown up for her inspectio...   \n",
       "4    The visitors poured through the castle gates i...   \n",
       "..                                                 ...   \n",
       "340  Let them die,\" said Queen Selyse.\\n\\tIt was th...   \n",
       "341  \"Snow?\" said Tormund Giantsbane. \"You look lik...   \n",
       "342  The Dornish prince was three days dying.\\n\\tHe...   \n",
       "343  The hill was a stony island in a sea of green....   \n",
       "344  I am no traitor,\" the Knight of Griffin's Roos...   \n",
       "\n",
       "                                               persons  \n",
       "0    [Waymar Royce, Gared, Wall, Royce, Ser Waymar ...  \n",
       "1          [B, Jon, Old Nan, Mance Rayder, Bran, Robb]  \n",
       "2                                   [At, Catelyn, Ned]  \n",
       "3       [Illyrio, Dany, Her, Drogo, Viserys, Khal, Be]  \n",
       "4    [Jaime Lannister, Tyrion Lannister, Ser, Rober...  \n",
       "..                                                 ...  \n",
       "340  [Ser Narbert, Devan Seaworth, Ser Brus, Ser Do...  \n",
       "341  [Melisandre, Mance, Jon Snow, Jon, Tormund Gia...  \n",
       "342  [Ser Barristan Selmy, Quentyn Martell, Ser, Rh...  \n",
       "343        [She, Dany, Daenerys, Drogon, Bay, Valyria]  \n",
       "344  [Kevan, Ser, Esco, Margaery, Mace, Aerys, Tyre...  \n",
       "\n",
       "[345 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d393c3ba-6030-498c-b678-2c046502b37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>persons</th>\n",
       "      <th>books_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue</td>\n",
       "      <td>\"We should start back,\" Gared urged as the woo...</td>\n",
       "      <td>[Waymar Royce, Gared, Wall, Royce, Ser Waymar ...</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bran</td>\n",
       "      <td>The morning had dawned clear and cold, with a ...</td>\n",
       "      <td>[B, Jon, Old Nan, Mance Rayder, Bran, Robb]</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Catelyn</td>\n",
       "      <td>Catelyn had never liked this godswood.\\n\\tShe ...</td>\n",
       "      <td>[At, Catelyn, Ned]</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Daenerys</td>\n",
       "      <td>Her brother held the gown up for her inspectio...</td>\n",
       "      <td>[Illyrio, Dany, Her, Drogo, Viserys, Khal, Be]</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Eddard</td>\n",
       "      <td>The visitors poured through the castle gates i...</td>\n",
       "      <td>[Jaime Lannister, Tyrion Lannister, Ser, Rober...</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>5</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Let them die,\" said Queen Selyse.\\n\\tIt was th...</td>\n",
       "      <td>[Ser Narbert, Devan Seaworth, Ser Brus, Ser Do...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>5</td>\n",
       "      <td>Trueborn Lord Of Winterfell.</td>\n",
       "      <td>\"Snow?\" said Tormund Giantsbane. \"You look lik...</td>\n",
       "      <td>[Melisandre, Mance, Jon Snow, Jon, Tormund Gia...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>5</td>\n",
       "      <td>The Queen'S Hand</td>\n",
       "      <td>The Dornish prince was three days dying.\\n\\tHe...</td>\n",
       "      <td>[Ser Barristan Selmy, Quentyn Martell, Ser, Rh...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>5</td>\n",
       "      <td>Daenerys</td>\n",
       "      <td>The hill was a stony island in a sea of green....</td>\n",
       "      <td>[She, Dany, Daenerys, Drogon, Bay, Valyria]</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>5</td>\n",
       "      <td>Epilogue</td>\n",
       "      <td>I am no traitor,\" the Knight of Griffin's Roos...</td>\n",
       "      <td>[Kevan, Ser, Esco, Margaery, Mace, Aerys, Tyre...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     book                         title  \\\n",
       "0       1                      Prologue   \n",
       "1       1                          Bran   \n",
       "2       1                       Catelyn   \n",
       "3       1                      Daenerys   \n",
       "4       1                        Eddard   \n",
       "..    ...                           ...   \n",
       "340     5                           Jon   \n",
       "341     5  Trueborn Lord Of Winterfell.   \n",
       "342     5              The Queen'S Hand   \n",
       "343     5                      Daenerys   \n",
       "344     5                      Epilogue   \n",
       "\n",
       "                                                  text  \\\n",
       "0    \"We should start back,\" Gared urged as the woo...   \n",
       "1    The morning had dawned clear and cold, with a ...   \n",
       "2    Catelyn had never liked this godswood.\\n\\tShe ...   \n",
       "3    Her brother held the gown up for her inspectio...   \n",
       "4    The visitors poured through the castle gates i...   \n",
       "..                                                 ...   \n",
       "340  Let them die,\" said Queen Selyse.\\n\\tIt was th...   \n",
       "341  \"Snow?\" said Tormund Giantsbane. \"You look lik...   \n",
       "342  The Dornish prince was three days dying.\\n\\tHe...   \n",
       "343  The hill was a stony island in a sea of green....   \n",
       "344  I am no traitor,\" the Knight of Griffin's Roos...   \n",
       "\n",
       "                                               persons            books_name  \n",
       "0    [Waymar Royce, Gared, Wall, Royce, Ser Waymar ...     A Game of Thrones  \n",
       "1          [B, Jon, Old Nan, Mance Rayder, Bran, Robb]     A Game of Thrones  \n",
       "2                                   [At, Catelyn, Ned]     A Game of Thrones  \n",
       "3       [Illyrio, Dany, Her, Drogo, Viserys, Khal, Be]     A Game of Thrones  \n",
       "4    [Jaime Lannister, Tyrion Lannister, Ser, Rober...     A Game of Thrones  \n",
       "..                                                 ...                   ...  \n",
       "340  [Ser Narbert, Devan Seaworth, Ser Brus, Ser Do...  A Dance with Dragons  \n",
       "341  [Melisandre, Mance, Jon Snow, Jon, Tormund Gia...  A Dance with Dragons  \n",
       "342  [Ser Barristan Selmy, Quentyn Martell, Ser, Rh...  A Dance with Dragons  \n",
       "343        [She, Dany, Daenerys, Drogon, Bay, Valyria]  A Dance with Dragons  \n",
       "344  [Kevan, Ser, Esco, Margaery, Mace, Aerys, Tyre...  A Dance with Dragons  \n",
       "\n",
       "[345 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dic = {1: 'A Game of Thrones', 2: 'A Clash of Kings', 3: 'A Storm of Swords', 4: 'A Feast for Crows', 5: 'A Dance with Dragons'}\n",
    "\n",
    "ner_df['books_name'] = ner_df.book.apply(lambda x: books_dic[x])\n",
    "ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d542e240-e611-45ff-b7fa-05b805f3cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1 = ner_df.iloc[2].persons[0]\n",
    "i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "212b4479-bf52-4459-a1b4-97418a4f42f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Game of Thrones'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2 = ner_df.iloc[2].books_name\n",
    "i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe8517e7-12a0-4509-a9ae-35eb17579fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>title_name</th>\n",
       "      <th>infobox_name</th>\n",
       "      <th>aliases</th>\n",
       "      <th>role</th>\n",
       "      <th>network_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>Stannis Baratheon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464123</td>\n",
       "      <td>0.424886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>Othor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>0.228750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>Desmera Redwyne</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316804</td>\n",
       "      <td>0.221763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Masha Heddle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.309655</td>\n",
       "      <td>0.216758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>Ulf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235689</td>\n",
       "      <td>0.164982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               character  title_name  infobox_name  aliases  role  \\\n",
       "index                                                               \n",
       "2627   Stannis Baratheon           0             0        1     0   \n",
       "1214               Othor           0             0        0     0   \n",
       "1226     Desmera Redwyne           0             0        0     0   \n",
       "1211        Masha Heddle           0             0        0     0   \n",
       "1224                 Ulf           0             0        0     0   \n",
       "\n",
       "       network_score      rank  \n",
       "index                           \n",
       "2627        0.464123  0.424886  \n",
       "1214        0.326786  0.228750  \n",
       "1226        0.316804  0.221763  \n",
       "1211        0.309655  0.216758  \n",
       "1224        0.235689  0.164982  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(get_corpus(i1,i2),i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b04f4f7-3cd3-4138-873b-0a8907aba0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Waymar Royce'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(get_corpus(i1,i2),i2).iloc[0].character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31a55649-6638-4751-8768-f97febd45db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "345it [01:46,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "characters_link = []\n",
    "characters_present = []\n",
    "\n",
    "for _,row in tqdm(ner_df.iterrows()):\n",
    "    book = row.books_name\n",
    "    persons = row.persons\n",
    "    characters_real_name = []\n",
    "    for person in persons:\n",
    "        search_result = predict(get_corpus(person,book),book)\n",
    "        if search_result.size:\n",
    "            search_result = search_result.iloc[0].character\n",
    "            characters_real_name.append(search_result)\n",
    "\n",
    "    characters_real_name = set(characters_real_name)\n",
    "    \n",
    "    for charac_link in characters_real_name:\n",
    "        \n",
    "        if charac_link in characters_present:            \n",
    "            for character in characters_link:\n",
    "                if character['name'] == charac_link:\n",
    "                    for charac_tmp in characters_real_name:\n",
    "                        if (charac_link != charac_tmp) and (charac_tmp not in character['links']):\n",
    "                            character['links'].append(charac_tmp)\n",
    "                            \n",
    "                    break\n",
    "                            \n",
    "        else:\n",
    "            characters_present.append(charac_link)\n",
    "            list = []\n",
    "            for charac_tmp in characters_real_name:\n",
    "                if charac_link != charac_tmp:\n",
    "                    list.append(charac_tmp)\n",
    "            characters_link.append({'name': charac_link, 'links': list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "abefcd11-fe0e-4542-be31-b18c249ee565",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(characters_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "15d73880-537a-41ac-a66b-5303f883087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "F = nx.DiGraph()\n",
    "for index, row in final_df.iterrows():\n",
    "    page = row['name']\n",
    "    for l in row['links']:\n",
    "        F.add_edge(page,l) # create the link between the node and its 'childrens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3e54f250-0abc-4956-b3a1-be70a3a4a8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14672"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a8e28012-f55f-42c2-9b2d-aa96e0a192e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "03c3e4cf-588b-4924-a393-ddc950b5830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list=[]\n",
    "for l in ner_df.persons.values:\n",
    "    full_list.extend(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f2494dd-d554-445f-802a-98bfe6d64ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(full_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2459ee1a-6fcb-4603-b623-28bca35394a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(F, 'final_exam.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85399d6d-6a8c-4e56-89d4-f71e6d0f3fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
